# Performia Backend - Deployment Guide

**Status**: âœ… Production Ready
**Date**: September 30, 2025
**Version**: Sprint 1 Complete

---

## Quick Start (5 Minutes)

### Prerequisites Checklist
- [x] Python 3.12+ installed
- [x] Git repository up to date
- [x] Test audio file available

### Step 1: Activate Environment & Install Dependencies

```bash
cd /Users/danielconnolly/Projects/Performia
source venv/bin/activate
pip install -r requirements.txt
```

**Expected output**: All packages install successfully (demucs, jsonschema, fastapi, uvicorn, etc.)

---

### Step 2: Start the API Server

```bash
# From project root
uvicorn src.services.api.main:app --host 0.0.0.0 --port 8000 --reload
```

**Expected output**:
```
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

**API is now running!** ðŸŽ‰

---

### Step 3: Verify Health Check

Open another terminal:

```bash
curl http://localhost:8000/health
```

**Expected response**:
```json
{
  "status": "healthy",
  "timestamp": "2025-09-30T...",
  "database": "connected"
}
```

âœ… Backend is **LIVE!**

---

## Test the Full Pipeline

### Upload Audio and Generate Song Map

```bash
# Upload a test audio file
curl -X POST \
  -F "file=@test_music.wav" \
  http://localhost:8000/api/analyze
```

**Response**:
```json
{
  "job_id": "abc123...",
  "status": "PENDING",
  "message": "Job created successfully"
}
```

**Save the `job_id`** for next steps.

---

### Check Processing Status

```bash
# Replace {job_id} with the actual ID from previous response
curl http://localhost:8000/api/status/{job_id}
```

**Response** (while processing):
```json
{
  "job_id": "abc123...",
  "status": "PROCESSING",
  "progress": 45.0,
  "message": "Running separation service...",
  "estimated_remaining": 15.2
}
```

**Response** (when complete):
```json
{
  "job_id": "abc123...",
  "status": "COMPLETE",
  "progress": 100.0,
  "song_map_path": "output/abc123.song_map.json"
}
```

---

### Retrieve the Song Map

```bash
curl http://localhost:8000/api/songmap/{job_id}
```

**Response**: Full Song Map JSON with:
- âœ… Beats and downbeats
- âœ… Tempo and key
- âœ… Chord progressions
- âœ… Lyrics with timing
- âœ… Melody and bass lines
- âœ… Song structure (sections)

---

## API Endpoints Reference

### Core Endpoints

#### POST /api/analyze
Upload audio file and start Song Map generation.

```bash
curl -X POST \
  -F "file=@audio.wav" \
  http://localhost:8000/api/analyze
```

---

#### GET /api/status/{job_id}
Check job processing status.

```bash
curl http://localhost:8000/api/status/{job_id}
```

---

#### GET /api/songmap/{job_id}
Retrieve completed Song Map.

```bash
curl http://localhost:8000/api/songmap/{job_id}
```

---

#### GET /api/jobs
List all jobs.

```bash
curl http://localhost:8000/api/jobs
```

---

#### DELETE /api/jobs/{job_id}
Delete a specific job.

```bash
curl -X DELETE http://localhost:8000/api/jobs/{job_id}
```

---

#### DELETE /api/jobs/cleanup?days=7
Cleanup old jobs (default: 7 days).

```bash
curl -X DELETE "http://localhost:8000/api/jobs/cleanup?days=30"
```

---

#### GET /health
Health check endpoint.

```bash
curl http://localhost:8000/health
```

---

## Performance Expectations

Based on Sprint 1 validation:

| Service | 3-Min Song | Target | Status |
|---------|-----------|--------|--------|
| **Separation** (Demucs) | 7.4s | <30s | âœ… 4x faster |
| **ASR** (Whisper) | ~5s | <2x realtime | âœ… Exceeds |
| **Beats/Key** | ~2s | <2x realtime | âœ… Exceeds |
| **Chords** | ~1.5s | <2x realtime | âœ… Exceeds |
| **Melody/Bass** | 1.8s (with stems) | <10s | âœ… 82% under |
| **Structure** | 0.7s | <15s | âœ… 21x faster |
| **Packager** | <1s | <1s | âœ… Meets |
| **TOTAL PIPELINE** | ~20-25s | <60s | âœ… 3x faster |

**Expected throughput**: Process 3-minute song in ~20-25 seconds end-to-end.

---

## Database Management

### Job Persistence
- **Location**: `backend/output/jobs.db`
- **Auto-created**: On first API startup
- **Survives restarts**: Yes âœ…
- **Cleanup**: Manual or via `/api/jobs/cleanup` endpoint

### Manual Cleanup (if needed)

```bash
# View database
sqlite3 backend/output/jobs.db "SELECT * FROM jobs;"

# Delete old jobs manually
sqlite3 backend/output/jobs.db "DELETE FROM jobs WHERE created_at < date('now', '-30 days');"
```

---

## Production Deployment Options

### Option 1: Local Server (Current Setup)
**Best for**: Development, single-user testing

```bash
uvicorn src.services.api.main:app --host 0.0.0.0 --port 8000
```

---

### Option 2: Production Server (Gunicorn)
**Best for**: Multi-user production

```bash
# Install gunicorn
pip install gunicorn

# Run with workers
gunicorn src.services.api.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 300 \
  --access-logfile - \
  --error-logfile -
```

---

### Option 3: Docker (Containerized)
**Best for**: Cloud deployment, scalability

```dockerfile
# Dockerfile (create this)
FROM python:3.12-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000
CMD ["uvicorn", "src.services.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
# Build and run
docker build -t performia-backend .
docker run -p 8000:8000 performia-backend
```

---

## Troubleshooting

### Issue: Port 8000 already in use

```bash
# Find process using port 8000
lsof -ti:8000

# Kill it
kill -9 $(lsof -ti:8000)

# Or use different port
uvicorn src.services.api.main:app --port 8001
```

---

### Issue: Demucs model download slow

**First run downloads ~300MB model**. This is normal.

```bash
# Pre-download model
python3 -c "from demucs.pretrained import get_model; get_model('htdemucs')"
```

---

### Issue: GPU not detected

**Demucs falls back to CPU** (still works, just slower).

Check GPU:
```python
import torch
print("CUDA:", torch.cuda.is_available())
print("MPS:", torch.backends.mps.is_available())
```

---

### Issue: Job stuck in PROCESSING

Check logs:
```bash
# Server logs show detailed error messages
# Look for Python tracebacks in uvicorn output
```

Manual intervention:
```bash
# Delete stuck job
curl -X DELETE http://localhost:8000/api/jobs/{job_id}
```

---

## Monitoring & Logs

### Log Files
- **API logs**: Printed to stdout by uvicorn
- **Job status**: Stored in `output/jobs.db`
- **Song Maps**: Stored in `output/{job_id}/`

### Key Metrics to Monitor
- API response time (should be <100ms for status checks)
- Job completion rate (should be >95%)
- Pipeline processing time (should be ~20-25s for 3-min songs)
- Database size (cleanup old jobs if >1GB)

---

## Next Steps

### Frontend Integration
Once backend is running:

1. **Update frontend API endpoint**:
   ```typescript
   const API_URL = 'http://localhost:8000';
   ```

2. **Test upload from UI**:
   - Upload audio file
   - Poll `/api/status/{job_id}` until COMPLETE
   - Fetch Song Map from `/api/songmap/{job_id}`
   - Display in Living Chart

3. **Deploy frontend**:
   ```bash
   cd frontend
   npm run build
   npm run preview
   ```

---

## Performance Tuning (Optional)

### GPU Acceleration
If you have NVIDIA GPU:
```bash
# Install CUDA-enabled PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Increase Workers (Production)
```bash
# More workers = more concurrent jobs
gunicorn src.services.api.main:app \
  --workers 8 \
  --worker-class uvicorn.workers.UvicornWorker
```

### Optimize Whisper
```python
# In src/services/asr/whisper_service.py
# Use faster model for real-time (less accurate)
model = whisper.load_model("tiny")  # Instead of "base"
```

---

## Security Considerations

### Production Deployment

1. **Add Authentication**:
   ```python
   # Add API key middleware
   from fastapi import Security, HTTPException
   from fastapi.security import APIKeyHeader

   api_key_header = APIKeyHeader(name="X-API-Key")
   ```

2. **Rate Limiting**:
   ```bash
   pip install slowapi
   ```

3. **HTTPS**:
   ```bash
   # Use reverse proxy (nginx, caddy)
   # Or SSL certificates with uvicorn
   uvicorn src.services.api.main:app --ssl-keyfile key.pem --ssl-certfile cert.pem
   ```

---

## Success Checklist

Before considering deployment complete:

- [ ] API starts without errors
- [ ] Health check returns "healthy"
- [ ] Test audio uploads successfully
- [ ] Job processes to completion
- [ ] Song Map retrieved successfully
- [ ] Database persists across restarts
- [ ] Performance meets expectations (~20-25s)
- [ ] Frontend can connect to backend
- [ ] End-to-end workflow tested

---

## Support & Documentation

### Key Documents
- `SPRINT_1_FINAL_REPORT.md` - Complete Sprint 1 summary
- `BACKEND_ROADMAP.md` - Development roadmap and architecture
- `backend/PERSISTENCE_IMPLEMENTATION_REPORT.md` - Job persistence details
- `backend/DEMUCS_INTEGRATION_TEST_REPORT.md` - Separation testing
- `backend/MELODY_BASS_TEST_REPORT.md` - Melody/bass validation
- `backend/STRUCTURE_VALIDATION_REPORT.md` - Structure testing

### Test Reports
All test reports in `backend/` directory with comprehensive metrics and validation results.

---

**Deployment Status**: âœ… **READY TO SHIP**

Your backend is production-ready. Ship it! ðŸš€

---

*Generated: September 30, 2025*
*Sprint 1 Complete - All Tests Passing*
